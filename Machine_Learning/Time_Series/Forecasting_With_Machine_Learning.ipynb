{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c13c04a",
   "metadata": {},
   "source": [
    "# Forecasting With Machine Learning\n",
    "Apply ML to any forecasting task with these four strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee12a71d",
   "metadata": {},
   "source": [
    "\n",
    "# üìò Lesson: Forecasting Beyond One Step Ahead\n",
    "\n",
    "## üß≠ Introduction\n",
    "\n",
    "In Lessons 2 and 3, we treated forecasting as a simple regression problem with all of our features derived from a single input: the **time index** ‚è≥. This allowed us to forecast any point in the future simply by generating the right **trend** and **seasonal** features.\n",
    "\n",
    "But once we added **lag features** in Lesson 4, the game changed üéÆ.  \n",
    "Lag features depend on knowing the past target value ‚Äî which isn‚Äôt available in the future!  \n",
    "A **lag 1** lets you predict one step ahead, but not two or more. ü§Ø\n",
    "\n",
    "In Lesson 4, we assumed we could always generate the necessary lags for each forecast (i.e., predicting just one step forward).  \n",
    "üîÆ **Real-world forecasting** usually requires more than this! So in this lesson, we‚Äôll learn how to forecast for multiple steps ahead using ML models.\n",
    "\n",
    "---\n",
    "\n",
    "## üìê Defining the Forecasting Task\n",
    "\n",
    "Before building a forecasting model, you need to define:\n",
    "\n",
    "1. üß† What **features** are available at the time of forecast?  \n",
    "2. ‚è∞ What **period** you‚Äôre forecasting into? (Target)\n",
    "\n",
    "### üîπ Forecast Origin\n",
    "The **forecast origin** is the time at which you are making a prediction.  \n",
    "üß© Typically, this is the last timestamp for which you have data.  \n",
    "Anything before this point can be used to generate features.\n",
    "\n",
    "### üîπ Forecast Horizon\n",
    "The **forecast horizon** is the time window you want to forecast ‚Äî e.g., a 1-step or 5-step horizon.  \n",
    "This defines your **target** üèÅ.\n",
    "\n",
    "### üîπ Lead Time\n",
    "The gap between the forecast origin and the start of the horizon is called the **lead time** (or **latency**).  \n",
    "‚è≥ A \"3-step ahead\" forecast means you're forecasting three time steps ahead of your most recent data.\n",
    "\n",
    "---\n",
    "\n",
    "## üõ†Ô∏è Preparing Data for Forecasting\n",
    "\n",
    "To use ML models for forecasting, we need to turn our time series üìä into a **dataframe** üßæ.\n",
    "\n",
    "We already did part of this in Lesson 4 when we created **lag features**.  \n",
    "Now, we also need to create our **target columns**, especially for **multistep forecasting**.\n",
    "\n",
    "### üßæ Example: Multistep Forecasting Table\n",
    "\n",
    "Each row = a **single forecast**  \n",
    "Each target column = one **future step**  \n",
    "Each feature column = one **past lag**\n",
    "\n",
    "| Year | y_step_3 | y_step_2 | y_step_1 | y_lag_2 | y_lag_3 | y_lag_4 | y_lag_5 | y_lag_6 |\n",
    "|------|----------|----------|----------|---------|---------|---------|---------|---------|\n",
    "| 2010 |   2      |   1      |   0      |   NaN   |   NaN   |   NaN   |   NaN   |   NaN   |\n",
    "| 2011 |   3      |   2      |   1      |   NaN   |   NaN   |   NaN   |   NaN   |   NaN   |\n",
    "| 2012 |   4      |   3      |   2      |    0    |   NaN   |   NaN   |   NaN   |   NaN   |\n",
    "| 2013 |   5      |   4      |   3      |    1    |    0    |   NaN   |   NaN   |   NaN   |\n",
    "| 2014 |   6      |   5      |   4      |    2    |    1    |    0    |   NaN   |   NaN   |\n",
    "| 2015 |   7      |   6      |   5      |    3    |    2    |    1    |    0    |   NaN   |\n",
    "| 2016 |   8      |   7      |   6      |    4    |    3    |    2    |    1    |    0    |\n",
    "| 2017 |   9      |   8      |   7      |    5    |    4    |    3    |    2    |    1    |\n",
    "| 2018 |  10      |   9      |   8      |    6    |    5    |    4    |    3    |    2    |\n",
    "| 2019 |  11      |  10      |   9      |    7    |    6    |    5    |    4    |    3    |\n",
    "\n",
    "> üîç This shows a **3-step forecast horizon** with a **2-step lead time** and **5 lag features**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Multistep Forecasting Strategies\n",
    "\n",
    "How do we make multistep forecasts from a model?  \n",
    "Here are **4 common strategies**, each with its own pros and cons:\n",
    "\n",
    "---\n",
    "\n",
    "### 1Ô∏è‚É£ Multioutput Model\n",
    "\n",
    "- üß† A single model that outputs multiple values (steps)\n",
    "- ‚úÖ Works great with models like **Linear Regression** and **Neural Networks**\n",
    "- ‚ùå Not compatible with models like **XGBoost**\n",
    "- üöÄ Efficient and simple!\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Direct Strategy\n",
    "\n",
    "- üéØ Train **a separate model for each time step**\n",
    "- E.g., 1 model for 1-step ahead, another for 2-steps ahead, etc.\n",
    "- ‚úÖ Each model is specialized üß™\n",
    "- ‚ùå Expensive to train (many models!)\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Recursive Strategy\n",
    "\n",
    "- üîÅ Train **one model** for 1-step ahead\n",
    "- Use its output as input (lag) for next step\n",
    "- ‚úÖ Only one model to train\n",
    "- ‚ùå Errors can accumulate üî∫\n",
    "\n",
    "---\n",
    "\n",
    "### 4Ô∏è‚É£ DirRec Strategy (Direct + Recursive)\n",
    "\n",
    "- üß¨ Hybrid approach!\n",
    "- Train **a model for each step**\n",
    "- Use **previous predictions as lags**\n",
    "- ‚úÖ Captures dependencies better than Direct\n",
    "- ‚ùå Still suffers from error propagation üò¨\n",
    "\n",
    "---\n",
    "\n",
    "üß† Which one is best? It depends on:\n",
    "- Forecast horizon ‚è≥\n",
    "- Data size üìà\n",
    "- Model type ü§ñ\n",
    "- Tolerance for error propagation üö®\n",
    "\n",
    "Now we‚Äôre ready to forecast like a pro! üåüüìâüìà Let's dive in!!\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff023fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samad\\AppData\\Local\\Temp\\ipykernel_35412\\3790485703.py:13: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  store_sales = pd.read_csv(\n",
      "C:\\Users\\samad\\AppData\\Local\\Temp\\ipykernel_35412\\3790485703.py:30: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  .groupby(['family', 'date'])\n",
      "C:\\Users\\samad\\AppData\\Local\\Temp\\ipykernel_35412\\3790485703.py:36: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  test = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "comp_dir = Path('store_sales_dataset')\n",
    "\n",
    "store_sales = pd.read_csv(\n",
    "    comp_dir / 'train.csv',\n",
    "    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'sales': 'float32',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "store_sales['date'] = store_sales.date.dt.to_period('D')\n",
    "store_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n",
    "\n",
    "family_sales = (\n",
    "    store_sales\n",
    "    .groupby(['family', 'date'])\n",
    "    .mean()\n",
    "    .unstack('family')\n",
    "    .loc['2017']\n",
    ")\n",
    "\n",
    "test = pd.read_csv(\n",
    "    comp_dir / 'test.csv',\n",
    "    dtype={\n",
    "        'store_nbr': 'category',\n",
    "        'family': 'category',\n",
    "        'onpromotion': 'uint32',\n",
    "    },\n",
    "    parse_dates=['date'],\n",
    "    infer_datetime_format=True,\n",
    ")\n",
    "test['date'] = test.date.dt.to_period('D')\n",
    "test = test.set_index(['store_nbr', 'family', 'date']).sort_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5dc9d3",
   "metadata": {},
   "source": [
    "Let's consider the following three forecasting tasks:\n",
    "\n",
    "a. 3-step forecast using 4 lag features with a 2-step lead time\n",
    "\n",
    "b. 1-step forecast using 3 lag features with a 1-step lead time\n",
    "\n",
    "c. 3-step forecast using 4 lag features with a 1-step lead time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7f9db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:222: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'Y' instead.\n",
      "  index=pd.period_range(start='2010', freq='A', periods=n, name='Year'),\n",
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:220: UserWarning: Instantiating Int8Dtype without any arguments.Pass a Int8Dtype instance to silence this warning.\n",
      "  ts = pd.Series(\n",
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:222: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'Y' instead.\n",
      "  index=pd.period_range(start='2010', freq='A', periods=n, name='Year'),\n",
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:220: UserWarning: Instantiating Int8Dtype without any arguments.Pass a Int8Dtype instance to silence this warning.\n",
      "  ts = pd.Series(\n",
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:222: FutureWarning: 'A' is deprecated and will be removed in a future version, please use 'Y' instead.\n",
      "  index=pd.period_range(start='2010', freq='A', periods=n, name='Year'),\n",
      "c:\\Users\\samad\\OneDrive\\Bureau\\ml\\times_series\\utils.py:220: UserWarning: Instantiating Int8Dtype without any arguments.Pass a Int8Dtype instance to silence this warning.\n",
      "  ts = pd.Series(\n"
     ]
    }
   ],
   "source": [
    "from utils import (create_multistep_example,\n",
    "                                          load_multistep_data,\n",
    "                                          make_lags,\n",
    "                                          make_multistep_target,\n",
    "                                          plot_multistep)\n",
    "datasets = load_multistep_data()\n",
    "\n",
    "data_tabs = widgets.Tab([widgets.Output() for _ in enumerate(datasets)])\n",
    "for i, df in enumerate(datasets):\n",
    "    data_tabs.set_title(i, f'Dataset {i+1}')\n",
    "    with data_tabs.children[i]:\n",
    "        display(df)\n",
    "\n",
    "display(data_tabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bf7f33",
   "metadata": {},
   "source": [
    "# 1) Match description to dataset\n",
    "task_a = 2\n",
    "\n",
    "task_b = 1\n",
    "\n",
    "task_c = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ad81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data\", \"\\n\" + \"-\" * 13 + \"\\n\", store_sales)\n",
    "print(\"\\n\")\n",
    "print(\"Test Data\", \"\\n\" + \"-\" * 9 + \"\\n\", test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35dd0b23",
   "metadata": {},
   "source": [
    "# 2) Identify the forecasting task for *Store Sales* competition\n",
    "\n",
    "The training set ends on 2017-08-15, which gives us the forecast origin. The test set comprises the dates 2017-08-16 to 2017-08-31, and this gives us the forecast horizon. There is one step between the origin and horizon, so we have a lead time of one day.\n",
    "\n",
    "Put another way, we need a 16-step forecast with a 1-step lead time. We can use lags starting with lag 1, and we make the entire 16-step forecast using features from 2017-08-15."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed3c190",
   "metadata": {},
   "source": [
    "# 3) Create multistep dataset for *Store Sales*\n",
    "Create targets suitable for the *Store Sales* forecasting task. Use 4 days of lag features. Drop any missing values from both targets and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2c75f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = family_sales.loc[:, 'sales']\n",
    "\n",
    "#Make 4 lag features\n",
    "X = make_lags(y, lags=4).dropna()\n",
    "\n",
    "#Make multistep target\n",
    "y = make_multistep_target(y, steps=16).dropna()\n",
    "\n",
    "y, X = y.align(X, join='inner', axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ac8f1b",
   "metadata": {},
   "source": [
    "Let's prepare the data for XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577b416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "X = (X\n",
    "    .stack('family')  # wide to long\n",
    "    .reset_index('family')  # convert index to column\n",
    "    .assign(family=lambda x: le.fit_transform(x.family))  # label encode\n",
    ")\n",
    "y = y.stack('family')  # wide to long\n",
    "\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40b566d",
   "metadata": {},
   "source": [
    "# 4) Forecast with the DirRec strategy\n",
    "Instatiate a model that applies the DirRec strategy to XGBoost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c621378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import RegressorChain\n",
    "\n",
    "model = RegressorChain(base_estimator=XGBRegressor())\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = pd.DataFrame(\n",
    "    model.predict(X),\n",
    "    index=y.index,\n",
    "    columns=y.columns,\n",
    ").clip(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7113c9",
   "metadata": {},
   "source": [
    "See a sample of the 16-step predictions this model makes on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fc1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "FAMILY = 'BEAUTY'\n",
    "START = '2017-04-01'\n",
    "EVERY = 16\n",
    "\n",
    "y_pred_ = y_pred.xs(FAMILY, level='family', axis=0).loc[START:]\n",
    "y_ = family_sales.loc[START:, 'sales'].loc[:, FAMILY]\n",
    "plot_params = {'figsize': (10, 6)}\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(11, 4))\n",
    "ax = y_.plot(**plot_params, ax=ax, alpha=0.5)\n",
    "ax = plot_multistep(y_pred_, ax=ax, every=EVERY)\n",
    "_ = ax.legend([FAMILY, FAMILY + ' Forecast'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
